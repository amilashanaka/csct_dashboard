{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import statistics\n",
    "import math\n",
    "\n",
    "#for LSTM model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import pymysql\n",
    "import json\n",
    "from app import app\n",
    "\n",
    "from flask import Flask, jsonify, request, make_response\n",
    "from flask import flash, request\n",
    "\n",
    "import datetime\n",
    "from werkzeug.security  import generate_password_hash, check_password_hash\n",
    "from functools import wraps\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.figsize':(9,7), 'figure.dpi':120})\n",
    "import pmdarima as pm\n",
    "\n",
    "#globally declare dataset\n",
    "data_set =pd.DataFrame()\n",
    "\n",
    "# Tranning dataset with\n",
    "\n",
    "tranning_data_set=pd.DataFrame()\n",
    "\n",
    "# Validation Data Set \n",
    "\n",
    "validate_data_set=pd.DataFrame()\n",
    "\n",
    "# result data set \n",
    "\n",
    "result_data_set=pd.DataFrame()\n",
    "\n",
    "\n",
    "def model_define():\n",
    "  # use predefined tranning data set\n",
    "  global tranning_data_set\n",
    "\n",
    "  # initialize the scaling method\n",
    "  scaler = MinMaxScaler()\n",
    "\n",
    "  #filter items an array \n",
    "\n",
    "  items = tranning_data_set.filter(['Items'])\n",
    "  items=items.values\n",
    "\n",
    "  items_length = math.ceil(len(items)*0.8)\n",
    "  # Normalize the data set\n",
    "  scaled_data=scaler.fit_transform(items)\n",
    "\n",
    "  # Create the training dataset\n",
    "  train_data = scaled_data[0 : items_length, :]\n",
    "\n",
    "  X_train = []\n",
    "  y_train = []\n",
    "  for i in range(0, len(train_data)):\n",
    "    X_train.append(train_data[i - items_length : i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "\n",
    "  #  make X_train and y_train np array\n",
    "  X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "  # reshape the data\n",
    "  X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1]))\n",
    "  print(X_train)\n",
    "\n",
    "   \n",
    "    \n",
    "  \n",
    "  return \"model_define\"\n",
    " \n",
    "\n",
    "\n",
    "@app.route('/start',methods=['POST'])\n",
    "\n",
    "def start():\n",
    "\n",
    "  global data_set\n",
    "  # read incomming json data \n",
    "  data=request.get_json()\n",
    "  # convert json data into pandas data structure\n",
    "  data_arr=json.dumps(data)\n",
    "  df=pd.read_json(data_arr)\n",
    "  df=df.transpose()\n",
    "\n",
    "  return_data = df.to_json()\n",
    "\n",
    "\n",
    "  return  return_data  \n",
    "\n",
    "\n",
    "@app.route('/tranning',methods=['POST'])\n",
    "\n",
    "def tranning():\n",
    "\n",
    "  global tranning_data_set\n",
    "  \n",
    "\n",
    "\n",
    "  # read incomming json data \n",
    "  data=request.get_json()\n",
    "\n",
    "  # convert json data into pandas data structure\n",
    "  data_arr=json.dumps(data)\n",
    "  tranning_data_set =pd.read_json(data_arr)\n",
    "  # tranning_data_set=tranning_data_set.T\n",
    "  \n",
    "  print(\"Tranning Start\")\n",
    "\n",
    "  # model_define()\n",
    "\n",
    "  return tranning_data_set.to_json()\n",
    "\n",
    "\n",
    "@app.route('/prediction',methods=['POST'])\n",
    "\n",
    "def prediction():\n",
    "  return \"prediction\"\n",
    "\n",
    "@app.route('/optimize',methods=['POST'])\n",
    "\n",
    "def optimize():\n",
    "  return \"optimize\"\n",
    "\n",
    "@app.route('/validate')\n",
    "\n",
    "def validate():\n",
    "  return \"validate\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ddeda93c9ca199fff51e902a980a778eab8b68d122b8281824354da7a3911ecd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
